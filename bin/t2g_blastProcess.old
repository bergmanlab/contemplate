#!/usr/bin/env python

from sys import *
from optparse import OptionParser
import glob
import os.path
import util
import tabfile

MAXMATCHES = 100 # ignore papers with more than x matches per chromosome
CHAINDIST = 100 # fuse two features from the same paper if they are closer than 100 bp and on the same strand

NAMESEP = "|" # separator between pmid and linecount
RESULTTRACKNAME="t2g_chainedFiltered" # the name of the track that includes the final bed information for further processing
RAWTRACKNAME="t2g_rawBlastHits"

# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = OptionParser("usage: %prog [options] inDir ctBedOutDir resultBedOutDir bestGenomesFile - convert *.blast-m8 files to UCSC custom tracks and to final bed file for further processing (determine best genome, filter out seqs with too many matches, chain adjacent matches) and output best genomes to bestGenomesFile") 

#parser.add_option("-l", "--wordlength", dest="motiflength", action="store", help="length of word [default: %default, hexamers]", type="int", metavar="NUMBER", default="6") 
#parser.add_option("-t", "--trackLine", dest="trackLine", action="store", help="add this to the start of all bed files", default='track name=textToGenome url=http://www.ncbi.nlm.nih.gov/pubmed/$$') 
parser.add_option("-p", "--prefix", dest="prefix", action="store", help="Only treat files in inDir that start with a given prefix", default="") 
parser.add_option("-t", "--taxonMapFile", dest="taxonFile", action="store", help="Map genome-codes to taxon ids, read genome-code to taxon-id mapping from this file, format: <genomeCode>tab<taxonId>, one per line", default=None) 
parser.add_option("-e", "--entrezFile", dest="entrezFile", action="store", help="Use the taxonMapFile to conver to taxonIds and compare with entrezGene's data using the entrezFile, format is <pmid>tab<taxonId>", default=None) 
(options, args) = parser.parse_args()

# ==== CLASSES =======
class Features(list):
    def __str__(self):
        buf = []
        for i in self:
            buf.append(str(i))
        return "\n".join(buf)

    def __sort__(self):
        self.sort(Feature.sort)

    def writeToFileHandle(self, fh):
        for b in self:
            fh.write(str(b)+"\n")

    def writeToFile(self, fname):
        fh = open(fname, "w")
        self.writeToFileHandle(fh)
        fh.close()

    def countChromosomes(self):
        chroms = set()
        for b in self:
            chroms.add(b.chrom)
        return len(chroms)

    def indexByChromAndName(self, stripCommentChar="_"):
        # return double hash chrom -> bedName (using only part before stripCommentChar) -> list of features
        idx = {}
        for f in self:
            name = f.name.split(stripCommentChar)[0]
            idx.setdefault(f.chrom, {}).setdefault(name, []).append(f)
        return idx

    def sort(self):
        self.sort(key=lambda f: f.start)

class Feature:
    def __init__(self, line):
        l = line.split()
        count = len(l)
        self.chrom = l[0]
        self.start = int(l[1])
        self.end = int(l[2])
        if count >= 4:
            self.name = l[3]
        if count >= 5:
            self.strand= l[4] 
        if count >= 6:
            self.score = int(l[5])

    def __init__(self,seqid="",start=0,end=0,name="",score=0,strand="+"):
        self.chrom = seqid
        self.start = int(start)
        self.end = int(end)
        self.name = name
        self.score = int(score)
        self.strand = strand

    def __str__(self):
        if "strand" in self.__dict__:
            return self.chrom+"\t"+str(self.start)+"\t"+str(self.end)+"\t"+self.name+"\t"+str(self.score)+"\t"+self.strand
        if "score" in self.__dict__:
            return self.chrom+"\t"+str(self.start)+"\t"+str(self.end)+"\t"+self.name+"\t"+str(self.score)
        if "name" in self.__dict__:
            return self.chrom+"\t"+str(self.start)+"\t"+str(self.end)+"\t"+self.name
        return self.chrom+"\t"+str(self.start)+"\t"+str(self.end)

    def includes(self, f, tol=0):
        if self.chrom!=f.chrom:
            return False
        else:
            if self.start-tol <= f.start and self.end+tol >= f.end:
                return True

    def closerThan(self, maxDist, f):
        return self.chrom==f.chrom and (abs(self.end - f.start) <= maxDist or abs(f.end - self.start) <=maxDist)

    def chain(self, f2):
        if self.chrom != f2.chrom:
            stderr.write("error: Cannot chain features on different chromosomes\n")
            exit(1)
        if self.start < f2.start:
            ft1 = self
            ft2 = f2
        else:
            ft1 = f2
            ft2 = self
        newft = Feature(ft1.chrom, ft1.start, f2.end, ft1.name+"+"+ft2.name, ft1.score, ".")
        return newft

    def sameCoordinates(self, f2):
        if self.chrom == f2.chrom and self.start == f2.start and self.end == f2.end:
            return True
        else:
            return False

        
# ==== FUNCTIONs =====

def toBed(fname, genome, genomeScores, log, filterSeqids=None):
    f = open(fname, "r")
    # example
    # 11495631        chr1    100.00  23      0       0       1       23      25500772        25500750        2e-05   46.1
    features = Features()
    for l in f:
        fs = l.split("\t")
        srcId, trgId, perc, len, dummy, dummy, dummy, len, trgStart, trgEnd, eVal, score = fs
        trgEnd = int(trgEnd)
        trgStart = int(trgStart)
        score = float(score)
        if trgEnd < trgStart:
            trgStart, trgEnd = trgEnd, trgStart
            strand="-"
        else:
            strand="+"
            
        srcId = srcId.replace("_",NAMESEP)
        if filterSeqids!=None and srcId in filterSeqids:
            log.log("   Ignored sequence %s as it matches EMVEC" % srcId)
            continue
        feat = Feature(trgId, trgStart, trgEnd, srcId, 0, strand)
        pmid = srcId.split(NAMESEP)[0]
        try:
            pmid = int(pmid)
        except:
            log.log("   Ignored feature %s as first field does not look like a valid pmid" % str(feat))
            continue
        feat.pmid = pmid
        features.append(feat)

        # keep track of score for this pmid & genome
        if genome!=None:
            genomeScores.setdefault(pmid, {}).setdefault(genome, []).append(score)
        #genomeScores[pmid][genome].append(score)
    return features

def outputToFiles(outData, ctOutDir, filtDir):
    # write tracks for manual inspection into ct-files with track lines
    for of, tracks in outData.iteritems():
        outfn = os.path.join(ctOutDir, of+".bed") # add dir to output file
        stderr.write("Writing to "+outfn+"\n")
        outfh = open(outfn, "w")
        for trackName, feats in tracks.iteritems():
            outfh.write('track name=%s url=http://www.ncbi.nlm.nih.gov/pubmed?term=$$ visibility=3\n' % trackName)
            feats.writeToFileHandle(outfh)
        outfh.close()

    # end results are written into raw bed tracks without track-lines
    # and without the bed-name-additional information
    for of, tracks in outData.iteritems():
        outfn = os.path.join(filtDir, of+".bed") # add dir to output file
        outfh = open(outfn, "w")
        stderr.write("Writing to "+outfn+"\n")
        feats = tracks[RESULTTRACKNAME]
        for f in feats:
            f.name = f.name.split(NAMESEP)[0]
        feats.writeToFileHandle(outfh)


def chainFilterFeats(feats):
    """ chain features that are closer than CHAINDIST bp into one single feature and return the resulting list"""
    def makeCoverFt(stack):
        """ create a single feature covering all features in the list stack """
        if len(stack)==1:
            return stack[0]
        else:
            ft1 = stack[0]
            startMin = min([ft.start for ft in stack])
            endMax   = max([ft.end   for ft in stack])
            # create a name for the new feature
            baseName = ft1.name.split(NAMESEP)[0]
            nameExts = []
            for f in stack:
                fs = f.name.split(NAMESEP)
                if len(fs) > 1:
                    nameExts.append(fs[1])
            name  = baseName+NAMESEP+"+".join(nameExts)

            # create a feature covering all features on the stack
            coverFt = Feature(ft1.chrom, startMin, endMax, name, ft1.score, ft1.strand)
            return coverFt

    #ignoredPapers = []
    newFts = Features()
    idx = feats.indexByChromAndName(NAMESEP)
    for chrom, chromidx in idx.iteritems(): 
        for name, feats in chromidx.iteritems():
            #if len(feats)>MAXMATCHES:
                #ignoredPapers.append(name)
                #continue
            feats.sort()
            stack = []
            for f in feats:
                if len(stack)==0:
                    stack.append(f)
                else:
                    lastFt = stack[-1]
                    if f.closerThan(CHAINDIST, lastFt):
                        stack.append(f)

                    else: # feature f is far away from the last feature in the stack
                        coverFt = makeCoverFt(stack)
                        newFts.append(coverFt)
                        stack = [f]
            # saving stack
            newFts.append(makeCoverFt(stack))

    return newFts

def logIgnored(log, outfn, ignoredPapers):
    log.log("%s: Ignored the following %d papers as they resulted in more than %d matches on a genome:" % (outfn, len(ignoredPapers), MAXMATCHES))
    for p, genomeHits in ignoredPapers.iteritems():
        strList = []
        for genome, hitCount in genomeHits.iteritems():
            strList.append("genome %s with %d hits" % (genome, hitCount))
        log.log("   "+str(p)+": "+",".join(strList))

def pmidBestGenome(pmidGenomeScores, outfile, log, scoreType="ecoli"):
    """ determine best genome per pmid """
    """ result are written as hash to outfile, complete debug info written to logger """
    """ scoreType can be either "sum" of all scores per genome or "max" of all scores per genome """
    """ or "ecoli" which is like max but ecoli has always preference """
    bestGenomes = {}
    for pmid, genomeScores in pmidGenomeScores.iteritems():
        #scores = genomeScores.items() # convert hash to list
        # convert hash with scoreList to sum of scores per genome and sort
        scores = []
        genomes = set()
        for genome, scoreList in genomeScores.iteritems():
            if scoreType=="sum":
                score = sum(scoreList)
            else:
                score = max(scoreList)
            scores.append( (genome, score) )
            genomes.add(genome)
        scores.sort( key= lambda (x,y): y, reverse=True) # sort list by 2nd member of pair

        # take best score and save result
        bestGenome = scores[0][0]
        if scoreType=="ecoli" and "ecoli" in genomes:
            bestGenome="ecoli"

        bestGenomes[pmid] = bestGenome
        log.log("   pmid=%s, genomeScores=%s, bestGenome=%s" % (pmid, str(scores), bestGenome))

    # write results to outfile
    of = open(outfile, "w")
    for pmid, bestGenome in bestGenomes.iteritems():
        #taxid = genomeToTaxid.get(bestGenome, bestGenome)
        of.write("%s\t%s\n" % (pmid, bestGenome))
    of.close()
    return bestGenomes

def readEntrezData(entrezFile):
    """ return pmid (int!) -> taxon (int!) dict """
    f = open(entrezFile)
    lines = f.read().splitlines()
    pmidToTaxon = {}
    for l in lines:
        fs = l.split()
        pmidToTaxon[int(fs[0])] = int(fs[1])
    del lines
    return pmidToTaxon

def tooManyMatches(pmidGenomeScores):
    """ return dict pmid -> list of genomes where pmid exceeded threshold MAXMATCHES """
    ignorePmids = {}
    for pmid, genomeScores in pmidGenomeScores.iteritems():
        for genome, scoreList in genomeScores.iteritems():
            if len(scoreList)>MAXMATCHES:
                ignorePmids.setdefault(pmid, {})
                ignorePmids[pmid][genome]=len(scoreList)
    return ignorePmids

#def genomeScoresToBest(pmidGenomesScores):
    #""" replace list of scores by best matching genome in pmidGenomesScores-dict """
    #bestGenome = {}
    #for pmid, genomeScores in bestGenomes.iteritems():
        #for genome, scoreList in genomeScores.iteritems():
            #newBestGenomes.setdefault(pmid, {})[genome]=sum(scoreList)
    #return bestGenomes

    #for pmid, bestGenome in bestGenomes.iteritems():
        # ignore all pmids that are not castable to int
        #try:
            #entrezTaxon = entrezPmidToTaxon.get(int(pmid), None)
        #except:
            #continue 
        # ignore all pmids that are not mappable to one of our genomes

def logT2gEntrezDiff(genomeToTaxon, entrezFile, bestGenomes):
    genomeToTaxid = tabfile.slurpdict(genomeToTaxon)
    ourTaxons = set([int(i) for i in genomeToTaxid.values()])

    log.log(" * Comparison of best genomes from blast matches with Entrez Genes data", toStderr=True)
    entrezPmidToTaxon = readEntrezData(entrezFile)

    count = 0
    goodTaxons = 0
    validationPapers = 0
    for pmid, entrezTaxon in entrezPmidToTaxon.iteritems():
        # ignore if no data from blast
        if not pmid in bestGenomes:
            continue
        # ignore if taxon in entrez is not in our list of genomes-of-interest:
        if not entrezTaxon in ourTaxons:
            continue
        validationPapers += 1

        ourGenome = bestGenomes[pmid]
        t2gTaxon = genomeToTaxid.get(ourGenome, 0)

        log.log("   pmid=%s, t2gGenome=%s, t2gTaxon=%s, entrezGeneTaxon=%s" % (pmid, ourGenome, t2gTaxon, entrezTaxon))
        if int(t2gTaxon)==int(entrezTaxon):
            count+=1
    log.log(" * Results of comparison with Entrez:", toStderr=True)
    log.log( "   Number of pmids with data after blast filtering AND in Entrez AND one of our genomes if interest: %d" % validationPapers, toStderr=True)
    #log.log( "   Number of pmids with one of our genomes (taxIds: %s, UCSCIds: %s): %d" % (str(ourTaxons), str(genomeToTaxid.values()), goodTaxons), toStderr=True)
    log.log( "   Absolute number of taxons we guessed correctly (true positives): %d" % count, toStderr=True)
    log.log( "   Share of true positives relative to all papers where we can guess (sequenced genome + nucleotides in paper): %f" % (float(count) / validationPapers), toStderr=True)
    #log.log( "   Share of true positives relative to all papers with nucleotides: %f" % (float(count) / goodTaxons), toStderr=True)

def parseEmvecFile(files):
    # Pull out the emvec file from our blast files and 
    # create a list of emvec-related sequence-identifiers 
    emvecFiles = [f for f in files if f.find("univec")!=-1]
    emvecIds = set()

    if len(emvecFiles)>1:
        stderr.write("Found too many files that look like emvec-blast-files: %s" % str(emvecFiles))
        exit(1)
    elif len(emvecFiles)==0:
        log.log("warning: Could not find EMVEC-database's blast files. Plasmid filtering desactivated.\n", toStderr=True)
    else:
        emvecFile = emvecFiles[0]
        files.remove(emvecFile)
        lines = open(emvecFile).readlines()
        for l in lines:
            id = l.split()[0]
            id = id.replace("_", NAMESEP)
            emvecIds.add(id)
        #feats=toBed(emvecFile, None, None, log)
        #for f in feats:
            #emvecIds.add(f.name)
        print emvecIds
    return files, emvecIds

# ----------- MAIN --------------
if args==[]: 
    parser.print_help()
    exit(1)

inDir, ctOutDir, filtOutDir, bestGenomesFile = args
prefix = options.prefix
genomeToTaxon = options.taxonFile
entrezFile = options.entrezFile

log = util.Logger()

# collect .blast files from dir
files = set(glob.glob(os.path.join(inDir, prefix+'*.blast')))
if len(files)==0:
    stderr.write("No input files found in directory %s.\n" % inDir)
    exit(1)

outData   = {} # dict: genome -> trackName -> bed lines without \n
pmidGenomeScores = {} # dict: 

# step 1: read in emvec, convert blast to bed without emvec-seqs and collect genome -> scores, keep raw features for custom track
log.log(" * Parsing EMVEC", onlyStderr=True)
files, emvecSeqids = parseEmvecFile(files)

log.log(" * Parsing blast files", toStderr=True)
for f in files:
    log.log("   Reading %s" % f, toStderr=False)
    genome = os.path.basename(f).split(".")[0] # strip chromosome info from input file
    feats=toBed(f, genome, pmidGenomeScores, log, emvecSeqids)
    outData.setdefault(genome,{}).setdefault(RAWTRACKNAME, Features()).extend(feats)

# step 2: determine best genome for each pmid
log.log(" * Identification of best genome for each pmid", toStderr=True)
bestGenomes = pmidBestGenome(pmidGenomeScores, bestGenomesFile, log)

# optional step 2b: compare our best genomes with entrez' gene taxon-ids
if entrezFile:
    if genomeToTaxon==None:
        stderr.write("Need taxon mapping file to compare with entrez\n")
        exit(1)
    logT2gEntrezDiff(genomeToTaxon, entrezFile, bestGenomes)

# step 3: filter out bed with pmids with too many matches on any genome and all beds
#         located on the wrong genome
log.log(" * Determining papers with too many matches on one genome", toStderr=True)
ignoredPapers = tooManyMatches(pmidGenomeScores)
if len(ignoredPapers)>0:
    logIgnored(log, f, ignoredPapers)
    #for i in ignoredPapers:
        #del pmidGenomeScores[i] # !!!


# step 4: chain resulting features 
for genome, trackFeats in outData.iteritems():
    log.log(" * Removing features of papers with too many matches in genome %s or if not best genome" % genome, onlyStderr=True)
    feats = trackFeats[RAWTRACKNAME]
    newFeats = Features()
    for f in feats:
        if not (f.pmid in ignoredPapers) and genome==bestGenomes[f.pmid]:
            newFeats.append(f)
    feats = newFeats

    log.log(" * Chaining features for %s" % genome, onlyStderr=True)
    log.log("   "+genome, onlyStderr=True)
    chainedFeats = chainFilterFeats(feats)
    outData.setdefault(genome,{}).setdefault(RESULTTRACKNAME, Features()).extend(chainedFeats)

outputToFiles(outData, ctOutDir, filtOutDir)
