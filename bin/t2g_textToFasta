#!/usr/bin/env python
from optparse import OptionParser
import sys, re, tarfile, glob, urllib2, socket, os

# This program is: Copyright by Maximilian Haeussler maximilianh@gmail.com
# It must not be modified nor made available to anyone without approval of the author

# used in Aerts, Haeussler et al, Genome Biology 2008 pubmed ID 18271954

# Thu Oct 30 18:24:24 CET 2008: added bergman mode and special case for logging, only active if domainname contains "agent"
# Thu Sep 17 18:01:58 BST 2009: addded split-primer mode by extending triplet recognition
# Thu Nov  5 10:46:27 GMT 2009: added inputDir and outputFile for Alf Eaton, removed logging system
# TODO: keep position of match in xml file for the fasta file 

MAXSEQS_DEFAULT = 100 # maximum number of sequences per file to be output

# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = OptionParser("usage: %prog [options] inputDir/InputFile outputFile - get all files that match fileWildcards, split text into words and parse out nucleotides using regular expressions, inputDir and its subdirectories is scanned for file extension xml by default, outputFile can be 'stdout' ") 

#parser.add_option("-l", "--wordlength", dest="motiflength", action="store", help="length of word [default: %default, hexamers]", type="int", metavar="NUMBER", default="6") 
#parser.add_option("-m", "--maf", dest="maf", action="store_true", help="force maf format [default: %default]", default=True) 
#parser.add_option("-c", "--concat", dest="concat", action="store", help="write concat'ed sequences for each file to this fasta file") 
#parser.add_option("-n", "--number", dest="number", action="store_true", help="add number individual sequences") 
parser.add_option("-m", "--minLen", dest="minLen", action="store", type="int", help="minimum length of dna sequences, default %default", default=17) 
parser.add_option("", "--maxSeqs", dest="maxSeqs", action="store", type="int", help="maximum number of sequences per file, default %default", default=MAXSEQS_DEFAULT) 
parser.add_option("", "--pmidFile", dest="pmidFile", action="store", type="string", help="File to write all pmids that are found", default=None) 
parser.add_option("-t", "--fileType", dest="fileType", action="store", help="type of file (currently only OTMI (nature) or xml (BMC)), will be guessed from file extension, used to treat lines and extract DOIs (as there is no pmid in the otmi-files)") 
parser.add_option("-p", "--pmc", dest="pmc", action="store_true", help="activate PMC mode: filenames is a directory with root folder of PMC. Will parse file_list.txt and PMC-ids.csv. Will iterate over all files from file_list, try to extract .txt and .nxml-files, parse them and convert ids using PMC_ids.csv to pubmed.ids.") 
parser.add_option("-b", "--bergmanMode", dest="bergmanMode", action="store_true", help="activate cBergmanMode: filename is a directory, the files are named <pmid>.txt and <pmid>.xml, each pmid has exactly two files, not more or less. .txt contains the ocr data, .xml contains the xml data. If there is no ocr data, the .txt file is empty and only the .xml file will be used. If .txt is not empty, ONLY the .txt file will be used.") 
parser.add_option("-w", "--wordSearch", dest="wordSearch", action="store", help="deactivate sequence search but just search for simple words, accepts a tabsep-table as input with format <word>tab<entity>, will output a table with pmid<tab>entity<tab>file to stdout") 
parser.add_option("-e", "--extension", dest="extension", action="store", help="the extension when searching for files, default is %default", default="xml") 
#parser.add_option("-l", "--logDir", dest="logDir", action="store", help="base directory for log-files, default is %default", default="log") 
#parser.add_option("-o", "--outFile", dest="outFile", action="store", help="file to write output to", default="log") 
(options, args) = parser.parse_args()
if args==[] or len(args)>2: 
    parser.print_help()
    sys.exit(1)

# ======= CONSTANTS =======
splitReStr = '[ <>.,]' # regular expression to split text into words
splitRe = re.compile(splitReStr)

nucl = "[ACTGUactgu]"
nuclRegex = re.compile(nucl) # regular expression that describes nucleotide letters
nonNucl = re.compile("[^ACTGactg]") # regular expression that describes non-nucleotide letters (used for cleaning)
allNuclRegex = re.compile(nucl+"*") # word made up of ONLY nucleotides

MINPARTLEN = 4 # minium number of nuclRegex matches to be concatted the next word (primers split by spaces)
MINWORDLEN = 17 # minimum length of word to be processed
MINDNA = 0.4 # minimum content of nucleotide letters within a word
MINDNALEN = options.minLen  # minimum length of dna string to be output
MAXSEQS = options.maxSeqs # maximum number of sequences per file to be output

# regex for BMC to find pubmed-id within file, example line: <pubid idtype="pmpid">15453911</pubid>
bmcRegEx = re.compile('<pubid idtype="pmpid">([0-9]*)</pubid>')
# tag that marks the start of the references in a bmc file
bmcRefStart = re.compile('<refgrp>')
# regex for otmi to find pmid-id within file
otmiRegex = re.compile('<atom:id>info:doi/([^<]*)</atom:id>')

# ====== CLASSES ======================
class doiResolver:
    def __init__(self):
        self.cache={}

    def convert(self, doi):
        if doi in self.cache:
            return self.cache[doi]

        url = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?term=%s&email=maximilianh@gmail.com" % doi
        try:
            xml = urllib2.urlopen(url)
        except:
            return "PmidNotFound/HTTPError"

        for l in xml:
            if l.find("<Id>")!=-1:
                # <Id>16027735</Id>
                pmid = l.strip().replace("<Id>","").replace("</Id>", "")
                # strip off part after first _!
                self.cache[doi]=pmid
                return pmid

# ==== FUNCTIONs =====
    
def parsePmcFolder(folder, pmidFh, wordDict, outFh):
    # read in list of filename -> pmcId
    # example:
    # 1c/f0/Environ_Health_Perspect-14-_-1475106.tar.gz	Environ Health Perspect. 1976 Apr; 14:153-159	pmcA1475106
    print("PMC mode: Parsing file_list.txt\n")
    lines = open(os.path.join(folder, "file_list.txt"), "r").readlines()[1:] # first line contains header
    lines = [l.split("\t") for l in lines]
    lines = [(a, c.strip().replace("pmcA", "PMC")) for a, b, c in lines] # strange, have to convert pmcA to PMC
    filesToPmcId = dict(lines)
    print("Found %d files\n" % len(filesToPmcId))
    # read in list pmcId -> pmid
    # example:
    # Breast Cancer Res,1465-5411,1465-542X,2000,3,1,55, ,PMC13900,11250746, 
    pmcfile = os.path.join(folder, "PMC-ids.csv.gz")
    if os.path.exists(pmcfile):
        sys.stderr.write("PMC mode: Extracting PMC-ids.csv.gz\n")
        ret = os.system("gunzip -f "+pmcfile)
        if ret != 0:
            sys.stderr.write("error: could not extract %s\n" % pmcfile)
            sys.exit(1)

    sys.stderr.write("pmc mode: parsing pmc-ids.csv\n")
    pmctopmid = {}
    dropped=0
    for l in open(os.path.join(folder, "pmc-ids.csv"), "r"):
        if l.startswith("journal"):
            continue
        fs = l.split(",") 
        pmc, pmid = fs[8], fs[9]
        if pmid=="0":
            pmid="pmidnotfound/pmidiszero:"+pmc
            dropped+=1
        pmctopmid[pmc]=pmid
    print("found %d pmc-ids mapped to pubmed-ids\n" % len(pmctopmid))
    print("found %d articles with pmid=0\n" % dropped)

    for file, pmcId in filesToPmcId.iteritems():
        file = os.path.join(folder,file)
    	if not os.path.exists(file):
            print("Could not find file %s, consider updating you pmc folder \n" % file)
            continue
        try:
            tf = tarfile.open(file)
        except:
            print("warning: cannot open file %s" % file)
            continue
        pmid = pmctopmid.get(pmcId, file)
        # try to extract .txt file from tar.gz-file
        try:
            for m in tf.getmembers():
                fullname = os.path.join(file,m.name)
                if m.name.endswith(".txt") and not m.name.endswith("license.txt"):
                    fh = tf.extractfile(m)
                    extractNucleotides(fh, fullname, outFh, None, pmid, pmidFh, wordDict)
                if m.name.endswith(".nxml"):
                    fh = tf.extractfile(m)
                    extractNucleotides(fh, fullname, outFh, None, pmid, pmidFh, wordDict)
        except:
            print("Exception when extracting file %s, try re-downloading it" % file)

def parseCBergmanFolder(folder, pmidFh, wordDict, outFh):
    """ parse a folder with .txt and .xml files, basename is pmids, each pmid has one text (ocr) and one xml file """
    if not os.path.isdir(folder):
        print("warning: input dir %s is not a directory, skipping it\n" % (folder))
        return

    # get list of all pmcids in this dir
    xmlfnames = [f.replace(".xml", "") for f in glob.glob(os.path.join(folder, "*.xml"))]
    txtfnames = [f.replace(".txt", "").replace(".pdf", "") for f in glob.glob(os.path.join(folder, "*.txt"))]
    pmcIds = set(xmlfnames).union(txtfnames)
    print ("Found files for %d pmcids in directory %s\n" % (len(pmcIds), folder))

    if len(pmcIds)==0:
        print("error: could not find any .xml or .txt files in directory %s\n" % folder)
        return

    for fnameBase in pmcIds:
        pmid = os.path.splitext(os.path.basename(fnameBase))[0]
        # try to extract from one of the txt files
        txtnames = [fnameBase+".txt", fnameBase+".pdf.txt"]
        textFound=False
        for txtname in txtnames:
            if os.path.exists(txtname) and os.path.getsize(txtname)!=0:
                fh = open(txtname)
                extractNucleotides(fh, txtname, outFh, None, pmid, pmidFh, wordDict)
                textFound=True
        # or, otherwise, from the xml file
        if not textFound:
            xmlname = fnameBase+".xml"
            fh = open(xmlname)
            extractNucleotides(fh, xmlname, outFh, None, pmid, pmidFh, wordDict)


doiResolver = doiResolver()
def searchPmid(line, filename, fileType):
    """ search for pmid given text and filetype """
    if fileType.lower()=="otmi":
        # otmi files do not contain pmids
        # we extract the doi instead
        # example: <atom:id>info:doi/10.1038/439149a</atom:id>
        doiMatch = otmiRegex.search(line)
        if doiMatch!=None:
            #line = line.strip()
            #doi = line.replace("<atom:id>info:doi/","").replace("</atom:id>", "")
            doi = doiMatch.group(1)
            pmid = doiResolver.convert(doi)
            return True, pmid
    # bmc files contain the pmid
    # example:
    if fileType.lower()=="xml" or fileType.lower()=="bmc":
        match = bmcRegEx.search(line)
        matchRef = bmcRefStart.search(line)
        # verify that match is BEFORE start of references
        if match!=None and (matchRef==None or matchRef.start()>match.start()): 
            pmid = match.group(1)
        else:
            pmid = filename
        return True, pmid

    return False, None

def extractNucleotides(fh, filename, outFh, fileType=None, pmid=None, pmidFh=None, wordDict=None):
    """ parse out all primers from publication text from filehandle fh, print result as fasta to stdout
        - filename is used when generating the fasta ids
        - fileType is the extension of the file, 
        - pmid can be optionally supplied from the calling function but will be guessed from file contents """
    if fileType==None:
        fileType = os.path.splitext(filename)[1].strip(".")

    # THE MOST IMPORTANT PART IN ALL THIS CLUTTER STARTS HERE
    seqno = 0
    seqs = []  # all sequences found
    count=0 # number of nucl string
    outData = []

    line = " ".join(fh.readlines()).replace("<aug>", "   ").replace("<acg>", "   ")
    # first try to extract pmid from xml file itself
    #if pmid==None:
        #pmidPresent, match = searchPmid(line, filename, fileType) # handler for OTMI/BMC
        #if pmidPresent:
            #pmid = match

    # if still not found, mark it
    if pmid==None:
        #pmid = os.path.basename(filename)
        pmid = os.path.splitext(os.path.basename(filename))[0]
    if pmidFh:
        pmidFh.write("%s\t%s\n" % (pmid, filename))

    words = splitRe.split(line) # split line into words with regular expr [<> ,.;]
    stack=[]

    # special case: just search for certain words
    if wordDict:
        for desc, regex in wordDict.iteritems():
            for m in regex.finditer(line):
                if m:
                    word = m.group()
                    seqs.append((desc, word))

    # normal case: search for nucleotides
    else:
        position=0
        for word in words:
            rawWord = word
            word = word.strip().replace("-","").replace("(","").replace(")","")

            # ignore for PMC's embedded formulas
            if word.startswith("MathType@"):
                continue

            # special case for consecutive stretches of nucleotides separated by spaces
            if len(word)>=3 and len(nuclRegex.findall(word))==len(word):
                stack.append(word)
                continue
            else:
                stackWord = "".join(stack)
                if len(stackWord)>=MINWORDLEN: # need at least 18 bp to be able to blast later
                    word="".join(stack)
                    rawWord=" ".join(stack)
                    stack=[]
                else:
                    stack=[]

            if len(word) > MINWORDLEN:
                # standard case: long enough nucleotide-word 
                # special case for RNA sequences -> DNA
                word = word.replace("U","T").replace("u","t")
                dnaContent = float(len(nuclRegex.findall(word))) / len(word)
                if dnaContent > MINDNA :
                    seq = nonNucl.sub("", word) # remove all non-nucleotide characters
                    if len(seq) > MINDNALEN and seq not in seqs:
                        id = "%s|%d file=%s dnaContent=%.2f raw=%s" % (pmid, count, filename, dnaContent, rawWord)
                        outData.append( (id, seq) )
                        seqs.append(seq)  
                        count+=1

    # output data of this file
    if wordDict:
        for desc, word in set(seqs):
            data = [str(pmid), desc, word]
            outFh.write("\t".join(data)+"\n")
    else:
        if len(seqs) < MAXSEQS:
            for id, seq in outData:
                outFh.write(">"+id+"\n")
                outFh.write(seq+"\n")
        else:
            print("info: ignoring file %s, max sequence number reached\n" % filename)


# IMPORTANT PART ENDS HERE

def readRegex(fname):
    """ parse file with key -> value pair on each line, key/value has 1:1 relationship"""
    """ key is regular expression, value is a description """
    if fname==None:
        return {}
    dict = {}
    for l in open(fname, "r"):
        fs = l.strip().split("\t")
        if l.startswith("#"):
            continue
        if not len(fs)>1:
            stderr.write("error: word search file does not contain two fields\n")
            exit(1)
        regex = re.compile(fs[0])
        desc = fs[1]
        if desc not in dict:
            dict[desc] = regex
        else:
            sys.stderr.write("info: file %s, hit key %s two times: %s -> %s\n" %(fname, key, key, val))
    return dict

def findSubdirFiles(baseDir, extension):
    """ traverse a baseDir and all subdirectories to find all files with a certain extension """
    result = []
    for root, dirs, files in os.walk(baseDir):
        for f in files:
            if os.path.splitext(f)[1]=="."+extension:
                result.append(os.path.join(root, f))
    return result

# ----------- MAIN --------------

pmcMode = options.pmc
fileType = options.fileType
pmidFile = options.pmidFile
#logDir = options.logDir
bergmanMode = options.bergmanMode
wordSearchFile = options.wordSearch
extension = options.extension
inFileDir = args[0]
outFile = args[1]

# if a wildcard is found, resolve all wildcards to filenames
# if not, text if infile is file
# if not, treat as basedir and search for all xml files

if "*" in inFileDir:
    files = glob.glob(inFileDir)
elif os.path.isfile(inFileDir):
    files = [inFileDir]
else:
    print "Getting a list of all filenames... (this can take a while)"
    files = findSubdirFiles(inFileDir, extension)
    print "Found %d files with extension %s in directory %s" % (len(files), extension, inFileDir)

# in wordSearchMode, nucleotides are not extracted
# instead we search for certain keywords
if wordSearchFile!=None:
    wordDict = readRegex(wordSearchFile)
else:
    wordDict = None

if pmidFile:
    pmidFh = open(pmidFile, "w")
else:
    pmidFh = None

if outFile=="stdout":
    outFh=sys.stdout
else:
    outFh=open(outFile, "w")

# iterate over files/directories (depending on mode)
for filename in files:
    if pmcMode:
        parsePmcFolder(filename, pmidFh, wordDict, outFh)
    elif bergmanMode:
        parseCBergmanFolder(filename, pmidFh, wordDict, outFh)
    else:
        fh = open(filename, "r")
        extractNucleotides(fh, filename, outFh, fileType, pmidFh=pmidFh, wordDict=wordDict)

